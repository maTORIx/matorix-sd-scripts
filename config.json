{
    "sd_scripts_path": "..\\sd-scripts",
    "output_dir": ".\\outputs",
    "save_model_as": "safetensors",
    "training_default_args": {
        "learning_rate": 1e-4,
        "batch_size": 3,
        "steps": 5000,
        "train_dataset_iter_times": 10,
        "regularization_dataset_iter_times": 1,
        "fliplr_aug": true,
        "color_aug": true,
        "random_crop": false,
        "shuffle_caption": true,
        "caption_dropout_rate": 0.05,
        "xformers": true,
        "options": [
            "--prior_loss_weight=1.0",
            "--mixed_precision=fp16",
            "--gradient_checkpointing"
        ]
    },
    "training_types": {
        "networks": {
            "LoRA": {
                "options": [
                    "--network_module=networks.lora",
                    "--network_dim=128",
                    "--network_alpha=64"
                ]
            },
            "LoRA3x3": {
                "options": [
                    "--network_module=networks.lora",
                    "--network_dim=64",
                    "--network_alpha=1",
                    "--network_args='conv_div=64' 'conv_alpha=1'"
                ]
            },
            "LoHA": {
                "options": [
                    "--network_module=lycoris.kohya",
                    "--network_dim=32",
                    "--network_alpha=1",
                    "--network_args='conv_div=32' 'conv_alpha=1' 'algo=loha'"
                ]
            },
            "LoCon": {
                "options": [
                    "--network_module=lycoris.kohya",
                    "--network_dim=64",
                    "--network_alpha=1",
                    "--network_args='conv_div=64' 'conv_alpha=1' 'algo=lora'"
                ]
            }
        },
        "optimizers": {
            "Adafactor": {
                "args": [
                    "relative_step=True",
                    "scale_parameter=True",
                    "warmup_init=True"
                ],
                "options": [
                    "--lr_scheduler=cosine_with_restarts",
                    "--lr_scheduler_num_cycles=4",
                    "--lr_warmup_steps=500"
                ]
            },
            "AdamW8bit": {
                "args": [],
                "options": [
                    "--lr_scheduler=cosine_with_restarts"
                ]
            }
        },
        "Lora3x3+Adafactor": [
            "--optimizer_type=Adafactor",
            "--optimizer_args='relative_step=True' 'scale_parameter=True' 'warmup_init=True'",
            "--network_module=networks.lora",
            "--network_args='conv_div=128' 'conv_alpha=64",
            "--mixed_precision=fp16",
            "--prior_loss_weight=1.0",
            "--gradient_checkpointing",
            "--network_dim=128",
            "--network_alpha=128",
            "--lr_scheduler=cosine_with_restarts",
            "--lr_scheduler_num_cycles=4",
            "--caption_dropout_rate=0.05",
            "--lr_warmup_steps=500"
        ]
    },
    "sample": {
        "default_prompt": "best quality, masterpiece",
        "default_negative_prompt": "low quality, bad quality",
        "sampler": "ddim",
        "interval_steps": 500
    },
    "tagger": {
        "blip_batch_size": 4,
        "caption_batch_size": 4
    },
    "generator": {
        "batch_size": 4,
        "sampler": "ddim",
        "steps": 20,
        "default_prompt": "",
        "default_negative_prompt": ""
    }
}