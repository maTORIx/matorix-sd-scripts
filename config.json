{
    "sd_scripts_path": "..\\sd-scripts",
    "output_dir": ".\\outputs",
    "save_model_as": "safetensors",
    "training_default_args": {
        "learning_rate": 1e-4,
        "batch_size": 2,
        "steps": 5000,
        "train_dataset_iter_times": 10,
        "regularization_dataset_iter_times": 1,
        "fliplr": true,
        "color_aug": true,
        "random_crop": false,
        "shuffle_caption": true,
        "caption_dropout_rate": 0.05,
        "xformers": true,
        "network": "LoRA",
        "optimizer": "Adafactor",
        "options": [
            "--prior_loss_weight=1.0",
            "--mixed_precision=bf16",
            "--gradient_checkpointing",
            "--max_grad_norm=0"
        ]
    },
    "training_types": {
        "networks": {
            "LoRA": {
                "options": [
                    "--network_module=networks.lora",
                    "--network_dim=32",
                    "--network_alpha=4"
                ]
            },
            "LoRA_Large": {
                "options": [
                    "--network_module=networks.lora",
                    "--network_dim=256",
                    "--network_alpha=128"
                ]
            },
            "LoRA3x3": {
                "options": [
                    "--network_module=networks.lora",
                    "--network_dim=64",
                    "--network_alpha=1",
                    "--network_args \"conv_div=64\" \"conv_alpha=1\""
                ]
            },
            "LoHA": {
                "options": [
                    "--network_module=lycoris.kohya",
                    "--network_dim=32",
                    "--network_alpha=1",
                    "--network_args \"conv_div=32\" \"conv_alpha=1\" \"algo=loha\""
                ]
            },
            "LoCon": {
                "options": [
                    "--network_module=lycoris.kohya",
                    "--network_dim=64",
                    "--network_alpha=1",
                    "--network_args \"conv_div=64\" \"conv_alpha=1\" \"algo=lora\""
                ]
            }
        },
        "optimizers": {
            "Adafactor": {
                "options": [
                    "--optimizer_type=Adafactor",
                    "--optimizer_args \"relative_step=False\" \"scale_parameter=False\" \"warmup_init=False\"",
                    "--lr_scheduler=constant_with_warmup",
                    "--lr_scheduler_num_cycles=4",
                    "--lr_warmup_steps=300"
                ]
            },
            "AdamW": {
                "options": [
                    "--optimizer_type=AdamW",
                    "--lr_scheduler=cosine_with_restarts"
                ]
            },
            "AdamW8bit": {
                "options": [
                    "--optimizer_type=AdamW8bit",
                    "--lr_scheduler=cosine_with_restarts"
                ]
            },
            "Lion": {
                "options": [
                    "--optimizer_type=Lion"
                ]
            }
        }
    },
    "sample": {
        "default_prompt": "best quality, masterpiece",
        "default_negative_prompt": "low quality, bad quality",
        "sampler": "euler_a",
        "interval_steps": 100,
        "samplers": ["euler_a","ddim","pndm","lms","euler","heun","dpm_2","dpm_2_a","dpmsolver","dpmsolver++","dpmsingle","k_lms","k_euler","k_euler_a","k_dpm_2","k_dpm_2_a"]
    },
    "tagger": {
        "blip_batch_size": 4,
        "caption_batch_size": 4
    },
    "generator": {
        "batch_size": 1,
        "steps": 28,
        "default_prompt": "",
        "default_negative_prompt": ""
    }
}